# Production Hardening Guide

## ğŸ›¡ï¸ Hardening Overview

This document describes all production hardening measures implemented to ensure the Telegram bot runs reliably 24/7 without timeouts, freezes, memory leaks, or zombie processes.

## âœ… Hardening Measures Implemented

### 1. Process Management

#### Process Isolation
- âœ… Each yt-dlp process runs in isolated working directory
- âœ… Processes don't inherit environment variables
- âœ… Process groups properly managed

#### Process Termination
- âœ… Automatic process termination on timeout
- âœ… Force kill on exceptions
- âœ… Process group termination (kills all children)
- âœ… Graceful shutdown (SIGTERM) before force kill (SIGKILL)

**Implementation**: `YtDlpService::forceKillProcess()`

#### Zombie Process Prevention
- âœ… Automatic cleanup of stuck processes
- âœ… Scheduled zombie process detection
- âœ… Manual cleanup command available

**Commands**:
```bash
# Dry-run (detect only)
php artisan process:cleanup-zombies

# Actually kill zombies
php artisan process:cleanup-zombies --kill
```

### 2. Memory Management

#### Job Memory Limits
- âœ… Per-job memory limit: 512MB (downloads)
- âœ… Per-job memory limit: 256MB (telegram)
- âœ… Memory usage logging
- âœ… Warnings when memory usage exceeds 90%

**Implementation**: `DownloadMediaJob::$memory`

#### Worker Memory Limits
- âœ… Supervisor memory limits per worker
- âœ… Automatic worker restart after N jobs
- âœ… Automatic worker restart after time limit

**Supervisor Config**:
```ini
memlimit=536870912  # 512MB for downloads workers
memlimit=268435456  # 256MB for telegram workers
```

### 3. Timeout Protection

#### Process Timeouts
- âœ… Execution timeout: 60 seconds
- âœ… Idle timeout: 60 seconds
- âœ… Automatic termination on timeout

#### Job Timeouts
- âœ… Job timeout: 60 seconds
- âœ… Queue retry timeout: 120 seconds
- âœ… Worker max execution time: 3600 seconds (1 hour)

### 4. File Cleanup Guarantees

#### Automatic Cleanup
- âœ… Cleanup in `finally` blocks (always executes)
- âœ… Shutdown function registration (fatal error protection)
- âœ… Retry mechanism for cleanup failures
- âœ… Fallback to system commands if needed

**Implementation**: `DownloadMediaJob::cleanup()`

#### Orphaned File Cleanup
- âœ… Scheduled cleanup job runs hourly
- âœ… Removes temp directories older than 2 hours
- âœ… Logs cleanup statistics

**Scheduled Job**: `CleanupOrphanedFilesJob`

### 5. Queue Worker Hardening

#### Worker Configuration
- âœ… Separate workers for different queue types
- âœ… Memory limits per worker
- âœ… Max jobs per worker (prevents memory leaks)
- âœ… Max time per worker (prevents infinite loops)
- âœ… Graceful shutdown handling

#### Supervisor Configuration
```ini
# Downloads Workers
numprocs=2
memlimit=536870912  # 512MB
--max-jobs=50
--max-time=3600

# Telegram Workers
numprocs=4
memlimit=268435456  # 256MB
--max-jobs=100
--max-time=3600
```

### 6. Error Handling

#### Exception Handling
- âœ… Try-catch blocks around all critical operations
- âœ… Process termination in finally blocks
- âœ… Cleanup guaranteed even on exceptions
- âœ… Comprehensive error logging

#### Failure Recovery
- âœ… Smart retry logic (only network/process errors)
- âœ… Failed job tracking
- âœ… User notification on permanent failures
- âœ… No retries for validation errors

### 7. Resource Monitoring

#### Health Checks
- âœ… Queue health check command
- âœ… Process monitoring
- âœ… Memory usage tracking
- âœ… Disk space monitoring

**Commands**:
```bash
php artisan queue:health
php artisan queue:health --detailed
php artisan process:cleanup-zombies
```

## ğŸ“‹ Production Checklist

### Pre-Deployment

- [ ] Supervisor configuration installed
- [ ] Memory limits configured appropriately
- [ ] Queue workers started and monitored
- [ ] Cleanup jobs scheduled
- [ ] Log rotation configured
- [ ] Disk space monitoring enabled
- [ ] Health check commands tested

### Runtime Monitoring

- [ ] Queue lengths monitored (< 100 jobs)
- [ ] Worker memory usage tracked
- [ ] Failed jobs reviewed regularly
- [ ] Zombie processes checked hourly
- [ ] Disk space checked daily
- [ ] Logs reviewed for errors

### Maintenance

- [ ] Cleanup jobs running successfully
- [ ] Orphaned files removed regularly
- [ ] Zombie processes killed automatically
- [ ] Workers restarting properly
- [ ] Memory leaks not occurring
- [ ] No timeout issues

## ğŸ”§ Configuration

### Environment Variables

```env
# Memory limits
PHP_MEMORY_LIMIT=512M

# Timeouts
DOWNLOAD_TIMEOUT=60

# Queue
QUEUE_CONNECTION=redis
REDIS_QUEUE_RETRY_AFTER=120
```

### Supervisor Configuration

See `supervisor/telegram-bot-workers.conf` for complete configuration.

**Key Settings**:
- `memlimit`: Memory limit per worker
- `stopwaitsecs`: Graceful shutdown timeout
- `stopsignal`: TERM (graceful) before KILL
- `max-jobs`: Restart after N jobs
- `max-time`: Restart after N seconds

### Scheduler Configuration

Add to `routes/console.php`:
```php
// Cleanup orphaned files hourly
Schedule::job(new \App\Jobs\CleanupOrphanedFilesJob())
    ->hourly()
    ->withoutOverlapping()
    ->onOneServer();

// Cleanup zombie processes every 30 minutes
Schedule::command('process:cleanup-zombies --kill')
    ->everyThirtyMinutes()
    ->withoutOverlapping()
    ->onOneServer();
```

## ğŸš¨ Troubleshooting

### High Memory Usage

1. **Check worker memory**:
   ```bash
   ps aux | grep queue:work | awk '{print $6/1024 " MB"}'
   ```

2. **Reduce worker count**:
   Edit supervisor config, reduce `numprocs`

3. **Lower max-jobs**:
   Reduce `--max-jobs` to restart workers more frequently

### Zombie Processes

1. **Detect zombies**:
   ```bash
   php artisan process:cleanup-zombies
   ```

2. **Kill zombies**:
   ```bash
   php artisan process:cleanup-zombies --kill
   ```

3. **Check for stuck processes**:
   ```bash
   ps aux | grep yt-dlp
   ```

### Orphaned Files

1. **Check temp directory**:
   ```bash
   du -sh storage/app/temp/downloads
   ```

2. **Manual cleanup**:
   ```bash
   find storage/app/temp/downloads -type d -mtime +2 -exec rm -rf {} +
   ```

3. **Verify cleanup job**:
   Check scheduler logs for `CleanupOrphanedFilesJob`

### Worker Crashes

1. **Check supervisor status**:
   ```bash
   sudo supervisorctl status
   ```

2. **Check logs**:
   ```bash
   tail -f storage/logs/queue-*.log
   ```

3. **Restart workers**:
   ```bash
   sudo supervisorctl restart telegram-bot-*-worker:*
   ```

## ğŸ“Š Monitoring Recommendations

### Metrics to Track

1. **Queue Metrics**:
   - Queue length (should be < 100)
   - Processing rate (jobs/minute)
   - Failed job rate (should be < 5%)

2. **Resource Metrics**:
   - Worker memory usage (should be stable)
   - Disk space usage (should not grow unbounded)
   - CPU usage (should be reasonable)

3. **Process Metrics**:
   - Active yt-dlp processes (should be < worker count)
   - Zombie process count (should be 0)
   - Process runtime (should be < timeout)

### Alerting Thresholds

- **Queue Length**: Alert if > 200 jobs
- **Failed Jobs**: Alert if > 10% failure rate
- **Memory Usage**: Alert if > 80% of limit
- **Disk Space**: Alert if < 10% free
- **Zombie Processes**: Alert if > 0

## ğŸ” Security Considerations

1. **Process Isolation**: Each job runs in isolated directory
2. **Command Injection**: URL validation prevents injection
3. **Resource Limits**: Memory and time limits prevent DoS
4. **File Permissions**: Temp files use restrictive permissions
5. **Cleanup**: Automatic cleanup prevents disk exhaustion

## ğŸ“ˆ Performance Optimization

### Worker Scaling

**Downloads Workers**:
- Start with 2 workers
- Scale up if queue backs up
- Monitor CPU usage
- Each worker: ~50-100MB RAM

**Telegram Workers**:
- Start with 4 workers
- Can scale to 8-10 workers
- Each worker: ~20-30MB RAM

### Queue Tuning

- **Downloads Queue**: Longer timeout (120s), fewer workers
- **Telegram Queue**: Shorter timeout (30s), more workers
- **Redis**: Tune `retry_after` based on job duration

## âœ… Verification

### Test Hardening Measures

1. **Process Termination**:
   ```bash
   # Start a long-running job, then kill worker
   # Verify process is terminated
   ps aux | grep yt-dlp
   ```

2. **Memory Limits**:
   ```bash
   # Monitor memory during job execution
   watch -n 1 'ps aux | grep queue:work'
   ```

3. **Cleanup**:
   ```bash
   # Create temp files, then check cleanup
   ls -la storage/app/temp/downloads
   ```

4. **Zombie Detection**:
   ```bash
   # Run cleanup command
   php artisan process:cleanup-zombies
   ```

## ğŸ¯ Success Criteria

The system is considered hardened when:

- âœ… No webhook timeouts (> 1 second)
- âœ… No server freezes
- âœ… No zombie processes accumulate
- âœ… No memory leaks
- âœ… No orphaned files accumulate
- âœ… Workers restart automatically
- âœ… Cleanup always executes
- âœ… Processes always terminate

---

**Version**: 1.0.0  
**Last Updated**: 2025-01-15  
**Status**: âœ… Production Ready
